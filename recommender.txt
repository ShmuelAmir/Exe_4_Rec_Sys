> library(dplyr)
> library(ggplot2)
> library(recommenderlab)
> library(crayon)
> library(tidyverse)
> 
> 
> # Load the data from the saved file
> load("recommender3.rdata")
> pdf("recommender.pdf")
> 
> 
> # ---------- Create the matrices ---------- #
> 
> # user-item rating matrix - reorganize ratings-df rows = users, cols = books, cells = rating
> M <- sparseMatrix(
+   i = as.integer(ratings$`User-ID`),
+   j = as.integer(ratings$ISBN),
+   x = ratings$`Book-Rating`,
+   dims = c(nlevels(ratings$`User-ID`), nlevels(ratings$ISBN)),
+   dimnames = list(levels(ratings$`User-ID`), levels(ratings$ISBN)),
+ )
> 
> UI <- new("realRatingMatrix", data = M)
> 
> rm(M, books, users)
> gc()
           used  (Mb) gc trigger   (Mb)   max used    (Mb)
Ncells  5054923 270.0    8397832  448.5    8397832   448.5
Vcells 71912850 548.7  422103424 3220.4 1562428729 11920.4
> 
> 
> # removing less than 3 quantile
> row.threshold <- quantile(rowCounts(UI))[[2]]
> col.threshold <- quantile(colCounts(UI))[[4]]
> UI.ratings <- UI[
+   rowCounts(UI) >= row.threshold, 
+   colCounts(UI) >= col.threshold
+ ]
> dim(UI.ratings@data)
[1]  4986 57337
> 
> # normalize the data
> UI.ratings.n <- normalize(UI.ratings)
> UI.ratings.n.vec <- as.vector(UI.ratings.n@data)
Warning message:
In .sparse2v(x) : sparse->dense coercion: allocating vector of size 2.1 GiB
> UI.ratings.n.vec <- UI.ratings.n.vec[UI.ratings.n.vec != 0]
> 
> hist(UI.ratings.n.vec, main = "Histogram of Normalized Ratings", xlab = "Normalized Rating")
> 
> save(ratings, UI.ratings, file = "temp.rdata")
> rm(ratings, UI.ratings.n, UI.ratings.n.vec, UI, row.threshold, col.threshold)
> gc()
           used  (Mb) gc trigger   (Mb)   max used    (Mb)
Ncells  4893115 261.4    8397832  448.5    8397832   448.5
Vcells 69929879 533.6  621188146 4739.3 1562428729 11920.4
> 
> 
> # ---------- The model ---------- #
> 
> # Train a model with holdout (k-fold)
> eval_sets <- evaluationScheme(
+   data = UI.ratings, 
+   method = "cross-validation",
+   train = 0.8, 
+   given = -1,
+   goodRating = 6, 
+   k = 5
+ )
as(<dgCMatrix>, "dgTMatrix") is deprecated since Matrix 1.5-0; do as(., "TsparseMatrix") instead
Warning message:
In .local(data, ...) :
  Dropping these users from the evaluation since they have fewer rating than specified in given!
These users are 1666, 4713
> 
> 
> known.data <- getData(eval_sets, "known")
> train.data <- getData(eval_sets, "train")
> unknown_data <- as(getData(eval_sets, "unknown"), "matrix")
> 
> load("temp.rdata")
> save(ratings, UI.ratings, eval_sets, file = "temp.rdata")
> rm(ratings, UI.ratings, eval_sets)
> gc()
           used  (Mb) gc trigger   (Mb)   max used    (Mb)
Ncells  4893766 261.4    8397832  448.5    8397832   448.5
Vcells 69787853 532.5  496950517 3791.5 1562428729 11920.4
> 
> 
> # ---------- functions ---------- #
> 
> num_rows <- nrow(known.data)
> batch_size <- num_rows / 10
> num_batches <- ceiling(num_rows / batch_size)
my.evaluate <- function(eval_recommender, n, method, param) {
+   all_predictions <- vector("list", num_batches)
+   
+   start <- Sys.time()
+   for (i in 1:num_batches) {
+     start_row <- (i - 1) * batch_size + 1
+     end_row <- min(i * batch_size, num_rows)
+     
+     current_batch <- known.data[start_row:end_row, ]
+     
+     predictions <- predict(
+       eval_recommender,
+       current_batch,
+       n = n,
+       type = "ratings"
+     )
+     
+     all_predictions[[i]] <- as(predictions, "matrix")
+     
+     end <- Sys.time()
+     print(paste("method:", method, "n:", n, "batch:", i, "time:", format(end - start)))
+     start <- end
+   }
+   
+   final_predictions <- do.call(rbind, all_predictions)
+   
+   
+   # calculate metrics
+   TP <- 0
+   FP <- 0
+   FN <- 0
+   TN <- 0
+   
+   
+   rows <- dim(final_predictions)[[1]]
+   cols <- dim(final_predictions)[[2]]
+   
+   for (i in 1:rows) {
+     for (j in 1:cols) {
+       curr_org <- unknown_data[i,j]
+       curr_pred <- final_predictions[i,j]
+       
+       
+       if (is.na(curr_org) || is.na(curr_pred)) {
+         next
+       }
+       
+       
+       if (curr_org > 5 & curr_pred > 5) {
+         TP = TP + 1
+       } else if (curr_org <= 5 & curr_pred <= 5) {
+         TN = TN + 1
+       } else if (curr_org > 5 & curr_pred <= 5) {
+         FN = FN + 1
+       } else if (curr_org <= 5 & curr_pred > 5) {
+         FP = FP + 1
+       }
+     }
+   }
+   
+   
+   TPR <- TP / (TP + FN) # Recall
+   FPR <- FP / (FP + TN)
+   Precision <- TP / (TP + FP)
+   return(list(method, n, param, TPR, FPR, Precision))
+ }
> 
> 
> # evaluate a list of methods for different numbers of books
> 
> models_to_evaluate <- list(
+   # list(name = "IBCF", param = list(method = "cosine")),
+   # list(name = "IBCF", param = list(method = "pearson")),
+   list(name = "UBCF", param = list(method = "cosine")),
+   list(name = "UBCF", param = list(method = "pearson")),
+   list(name = "RANDOM", param = NULL) 
+ )
> 
> n_recommendations <- c(1, 3, 5, 10, 15, 20)
> 
> result <- list()
> 
> for (model in models_to_evaluate) {
+   rec <- my.recommender(model$name, model$param)
+   
+   for (n in n_recommendations) {
+     result <- append(result, my.evaluate(rec, n, model$name, model$param))
+   }
+ }
[1] "method: UBCF n: 1 batch: 1 time: 10.75857 mins"
[1] "method: UBCF n: 1 batch: 2 time: 9.041593 mins"
[1] "method: UBCF n: 1 batch: 3 time: 8.921846 mins"
[1] "method: UBCF n: 1 batch: 4 time: 8.600578 mins"
[1] "method: UBCF n: 1 batch: 5 time: 7.792807 mins"
[1] "method: UBCF n: 1 batch: 6 time: 7.005476 mins"
[1] "method: UBCF n: 1 batch: 7 time: 6.924221 mins"
[1] "method: UBCF n: 1 batch: 8 time: 7.045491 mins"
[1] "method: UBCF n: 1 batch: 9 time: 7.091165 mins"
[1] "method: UBCF n: 1 batch: 10 time: 6.872097 mins"
[1] "method: UBCF n: 3 batch: 1 time: 6.80129 mins"
[1] "method: UBCF n: 3 batch: 2 time: 7.01104 mins"
[1] "method: UBCF n: 3 batch: 3 time: 6.83154 mins"
[1] "method: UBCF n: 3 batch: 4 time: 6.948298 mins"
[1] "method: UBCF n: 3 batch: 5 time: 6.860456 mins"
[1] "method: UBCF n: 3 batch: 6 time: 6.905132 mins"
[1] "method: UBCF n: 3 batch: 7 time: 7.052657 mins"
[1] "method: UBCF n: 3 batch: 8 time: 7.090374 mins"
[1] "method: UBCF n: 3 batch: 9 time: 7.02237 mins"
[1] "method: UBCF n: 3 batch: 10 time: 6.91731 mins"
[1] "method: UBCF n: 5 batch: 1 time: 6.904079 mins"
[1] "method: UBCF n: 5 batch: 2 time: 7.00915 mins"
[1] "method: UBCF n: 5 batch: 3 time: 6.842877 mins"
[1] "method: UBCF n: 5 batch: 4 time: 7.057633 mins"
[1] "method: UBCF n: 5 batch: 5 time: 7.01891 mins"
[1] "method: UBCF n: 5 batch: 6 time: 7.0696 mins"
[1] "method: UBCF n: 5 batch: 7 time: 6.898687 mins"
[1] "method: UBCF n: 5 batch: 8 time: 6.560198 mins"
[1] "method: UBCF n: 5 batch: 9 time: 7.103502 mins"
[1] "method: UBCF n: 5 batch: 10 time: 6.808509 mins"
[1] "method: UBCF n: 10 batch: 1 time: 6.795687 mins"
[1] "method: UBCF n: 10 batch: 2 time: 7.159114 mins"
[1] "method: UBCF n: 10 batch: 3 time: 7.095418 mins"
[1] "method: UBCF n: 10 batch: 4 time: 6.945287 mins"
[1] "method: UBCF n: 10 batch: 5 time: 6.97117 mins"
[1] "method: UBCF n: 10 batch: 6 time: 7.020709 mins"
[1] "method: UBCF n: 10 batch: 7 time: 7.037311 mins"
[1] "method: UBCF n: 10 batch: 8 time: 6.707426 mins"
[1] "method: UBCF n: 10 batch: 9 time: 6.955974 mins"
[1] "method: UBCF n: 10 batch: 10 time: 6.992356 mins"
[1] "method: UBCF n: 15 batch: 1 time: 7.084271 mins"
[1] "method: UBCF n: 15 batch: 2 time: 6.789111 mins"
[1] "method: UBCF n: 15 batch: 3 time: 6.965068 mins"
[1] "method: UBCF n: 15 batch: 4 time: 6.98729 mins"
[1] "method: UBCF n: 15 batch: 5 time: 6.990766 mins"
[1] "method: UBCF n: 15 batch: 6 time: 6.462951 mins"
[1] "method: UBCF n: 15 batch: 7 time: 6.801567 mins"
[1] "method: UBCF n: 15 batch: 8 time: 6.674265 mins"
[1] "method: UBCF n: 15 batch: 9 time: 7.0094 mins"
[1] "method: UBCF n: 15 batch: 10 time: 6.789821 mins"
[1] "method: UBCF n: 20 batch: 1 time: 6.769535 mins"
[1] "method: UBCF n: 20 batch: 2 time: 6.479991 mins"
[1] "method: UBCF n: 20 batch: 3 time: 6.962661 mins"
[1] "method: UBCF n: 20 batch: 4 time: 6.578695 mins"
[1] "method: UBCF n: 20 batch: 5 time: 6.873216 mins"
[1] "method: UBCF n: 20 batch: 6 time: 6.80976 mins"
[1] "method: UBCF n: 20 batch: 7 time: 7.011238 mins"
[1] "method: UBCF n: 20 batch: 8 time: 6.808743 mins"
[1] "method: UBCF n: 20 batch: 9 time: 6.859565 mins"
[1] "method: UBCF n: 20 batch: 10 time: 6.944313 mins"
[1] "method: UBCF n: 1 batch: 1 time: 1.027312 mins"
[1] "method: UBCF n: 1 batch: 2 time: 1.006657 mins"
[1] "method: UBCF n: 1 batch: 3 time: 1.020336 mins"
[1] "method: UBCF n: 1 batch: 4 time: 1.018122 mins"
[1] "method: UBCF n: 1 batch: 5 time: 59.20727 secs"
[1] "method: UBCF n: 1 batch: 6 time: 1.013832 mins"
[1] "method: UBCF n: 1 batch: 7 time: 58.31045 secs"
[1] "method: UBCF n: 1 batch: 8 time: 57.63015 secs"
[1] "method: UBCF n: 1 batch: 9 time: 59.55098 secs"
[1] "method: UBCF n: 1 batch: 10 time: 1.005154 mins"
[1] "method: UBCF n: 3 batch: 1 time: 1.019457 mins"
[1] "method: UBCF n: 3 batch: 2 time: 58.97175 secs"
[1] "method: UBCF n: 3 batch: 3 time: 57.97726 secs"
[1] "method: UBCF n: 3 batch: 4 time: 1.036607 mins"
[1] "method: UBCF n: 3 batch: 5 time: 1.036402 mins"
[1] "method: UBCF n: 3 batch: 6 time: 1.004079 mins"
[1] "method: UBCF n: 3 batch: 7 time: 58.05651 secs"
[1] "method: UBCF n: 3 batch: 8 time: 58.72739 secs"
[1] "method: UBCF n: 3 batch: 9 time: 1.063432 mins"
[1] "method: UBCF n: 3 batch: 10 time: 1.071893 mins"
[1] "method: UBCF n: 5 batch: 1 time: 57.87601 secs"
[1] "method: UBCF n: 5 batch: 2 time: 1.022849 mins"
[1] "method: UBCF n: 5 batch: 3 time: 1.130276 mins"
[1] "method: UBCF n: 5 batch: 4 time: 1.027844 mins"
[1] "method: UBCF n: 5 batch: 5 time: 58.12299 secs"
[1] "method: UBCF n: 5 batch: 6 time: 1.048138 mins"
[1] "method: UBCF n: 5 batch: 7 time: 58.98228 secs"
[1] "method: UBCF n: 5 batch: 8 time: 59.81713 secs"
[1] "method: UBCF n: 5 batch: 9 time: 1.047688 mins"
[1] "method: UBCF n: 5 batch: 10 time: 59.04083 secs"
[1] "method: UBCF n: 10 batch: 1 time: 1.003732 mins"
[1] "method: UBCF n: 10 batch: 2 time: 1.005421 mins"
[1] "method: UBCF n: 10 batch: 3 time: 1.031085 mins"
[1] "method: UBCF n: 10 batch: 4 time: 1.080026 mins"
[1] "method: UBCF n: 10 batch: 5 time: 1.263196 mins"
[1] "method: UBCF n: 10 batch: 6 time: 57.22501 secs"
[1] "method: UBCF n: 10 batch: 7 time: 1.199005 mins"
[1] "method: UBCF n: 10 batch: 8 time: 1.056624 mins"
[1] "method: UBCF n: 10 batch: 9 time: 1.10473 mins"
[1] "method: UBCF n: 10 batch: 10 time: 1.083786 mins"
[1] "method: UBCF n: 15 batch: 1 time: 1.078886 mins"
[1] "method: UBCF n: 15 batch: 2 time: 1.042973 mins"
[1] "method: UBCF n: 15 batch: 3 time: 1.017936 mins"
[1] "method: UBCF n: 15 batch: 4 time: 1.189878 mins"
[1] "method: UBCF n: 15 batch: 5 time: 57.71549 secs"
[1] "method: UBCF n: 15 batch: 6 time: 1.046442 mins"
[1] "method: UBCF n: 15 batch: 7 time: 58.09129 secs"
[1] "method: UBCF n: 15 batch: 8 time: 1.123869 mins"
[1] "method: UBCF n: 15 batch: 9 time: 1.038807 mins"
[1] "method: UBCF n: 15 batch: 10 time: 55.4737 secs"
[1] "method: UBCF n: 20 batch: 1 time: 1.025705 mins"
[1] "method: UBCF n: 20 batch: 2 time: 1.106839 mins"
[1] "method: UBCF n: 20 batch: 3 time: 1.005753 mins"
[1] "method: UBCF n: 20 batch: 4 time: 58.25691 secs"
[1] "method: UBCF n: 20 batch: 5 time: 58.0796 secs"
[1] "method: UBCF n: 20 batch: 6 time: 56.98183 secs"
[1] "method: UBCF n: 20 batch: 7 time: 1.040418 mins"
[1] "method: UBCF n: 20 batch: 8 time: 1.019381 mins"
[1] "method: UBCF n: 20 batch: 9 time: 1.15147 mins"
[1] "method: UBCF n: 20 batch: 10 time: 57.24549 secs"
[1] "method: RANDOM n: 1 batch: 1 time: 1.543404 secs"
[1] "method: RANDOM n: 1 batch: 2 time: 1.362089 secs"
[1] "method: RANDOM n: 1 batch: 3 time: 1.582428 secs"
[1] "method: RANDOM n: 1 batch: 4 time: 1.364387 secs"
[1] "method: RANDOM n: 1 batch: 5 time: 1.547483 secs"
[1] "method: RANDOM n: 1 batch: 6 time: 1.357846 secs"
[1] "method: RANDOM n: 1 batch: 7 time: 1.549623 secs"
[1] "method: RANDOM n: 1 batch: 8 time: 1.462097 secs"
[1] "method: RANDOM n: 1 batch: 9 time: 1.362036 secs"
[1] "method: RANDOM n: 1 batch: 10 time: 1.561689 secs"
[1] "method: RANDOM n: 3 batch: 1 time: 1.36 secs"
[1] "method: RANDOM n: 3 batch: 2 time: 1.568657 secs"
[1] "method: RANDOM n: 3 batch: 3 time: 1.492527 secs"
[1] "method: RANDOM n: 3 batch: 4 time: 1.479901 secs"
[1] "method: RANDOM n: 3 batch: 5 time: 1.495232 secs"
[1] "method: RANDOM n: 3 batch: 6 time: 1.487612 secs"
[1] "method: RANDOM n: 3 batch: 7 time: 1.884337 secs"
[1] "method: RANDOM n: 3 batch: 8 time: 1.529392 secs"
[1] "method: RANDOM n: 3 batch: 9 time: 1.449754 secs"
[1] "method: RANDOM n: 3 batch: 10 time: 1.520577 secs"
[1] "method: RANDOM n: 5 batch: 1 time: 1.367366 secs"
[1] "method: RANDOM n: 5 batch: 2 time: 1.532077 secs"
[1] "method: RANDOM n: 5 batch: 3 time: 1.371452 secs"
[1] "method: RANDOM n: 5 batch: 4 time: 1.85847 secs"
[1] "method: RANDOM n: 5 batch: 5 time: 1.338656 secs"
[1] "method: RANDOM n: 5 batch: 6 time: 1.52678 secs"
[1] "method: RANDOM n: 5 batch: 7 time: 1.52893 secs"
[1] "method: RANDOM n: 5 batch: 8 time: 1.443379 secs"
[1] "method: RANDOM n: 5 batch: 9 time: 1.470983 secs"
[1] "method: RANDOM n: 5 batch: 10 time: 1.631454 secs"
[1] "method: RANDOM n: 10 batch: 1 time: 1.353073 secs"
[1] "method: RANDOM n: 10 batch: 2 time: 1.606137 secs"
[1] "method: RANDOM n: 10 batch: 3 time: 1.406705 secs"
[1] "method: RANDOM n: 10 batch: 4 time: 1.748994 secs"
[1] "method: RANDOM n: 10 batch: 5 time: 1.443543 secs"
[1] "method: RANDOM n: 10 batch: 6 time: 1.358213 secs"
[1] "method: RANDOM n: 10 batch: 7 time: 1.566322 secs"
[1] "method: RANDOM n: 10 batch: 8 time: 1.483339 secs"
[1] "method: RANDOM n: 10 batch: 9 time: 1.468388 secs"
[1] "method: RANDOM n: 10 batch: 10 time: 1.608353 secs"
[1] "method: RANDOM n: 15 batch: 1 time: 1.376402 secs"
[1] "method: RANDOM n: 15 batch: 2 time: 1.599367 secs"
[1] "method: RANDOM n: 15 batch: 3 time: 1.400591 secs"
[1] "method: RANDOM n: 15 batch: 4 time: 1.774753 secs"
[1] "method: RANDOM n: 15 batch: 5 time: 1.403091 secs"
[1] "method: RANDOM n: 15 batch: 6 time: 1.477799 secs"
[1] "method: RANDOM n: 15 batch: 7 time: 1.596571 secs"
[1] "method: RANDOM n: 15 batch: 8 time: 1.433573 secs"
[1] "method: RANDOM n: 15 batch: 9 time: 1.499825 secs"
[1] "method: RANDOM n: 15 batch: 10 time: 1.594041 secs"
[1] "method: RANDOM n: 20 batch: 1 time: 1.369492 secs"
[1] "method: RANDOM n: 20 batch: 2 time: 1.544177 secs"
[1] "method: RANDOM n: 20 batch: 3 time: 1.433538 secs"
[1] "method: RANDOM n: 20 batch: 4 time: 1.798346 secs"
[1] "method: RANDOM n: 20 batch: 5 time: 1.316637 secs"
[1] "method: RANDOM n: 20 batch: 6 time: 1.490154 secs"
[1] "method: RANDOM n: 20 batch: 7 time: 1.535899 secs"
[1] "method: RANDOM n: 20 batch: 8 time: 1.472765 secs"
[1] "method: RANDOM n: 20 batch: 9 time: 1.556925 secs"
[1] "method: RANDOM n: 20 batch: 10 time: 1.437322 secs"
There were 50 or more warnings (use warnings() to see the first 50)

df %>%
+   ggplot(aes(FPR, TPR, color = as.factor(method))) +
+   geom_line() 
> df %>%
+   ggplot(aes(FPR, TPR, color = as.factor(method))) +
+   geom_line() +
+   geom_label(aes(label = n)) +
+   labs(title = "ROC curves", colour = "Model") +
+   theme_grey(base_size = 14)
> df %>%
+   ggplot(aes(FPR, TPR, color = method)) +
+   geom_line() +
+   geom_label(aes(label = n)) +
+   labs(title = "ROC curves", colour = "Model") +
+   theme_grey(base_size = 14)
> df %>%
+   ggplot(aes(TPR, Precision, colour = method)) +
+   geom_line() +
+   geom_label(aes(label = n))  +
+   labs(title = "Precision-Recall curves", colour = "Model") +
+   theme_grey(base_size = 14)
> # create data.frame from the list
> col_num <- 6
> row_num <- length(result) / col_num
> 
> data_matrix <- matrix(result, ncol = col_num, byrow = TRUE)
> colnames(data_matrix) <- c("method", "n", "param", "TPR", "FPR", "Precision")
> 
> data_df <- as.data.frame(data_matrix, row.names = NULL)
> data_df <- lapply(data_df, function(x) c(unlist(x)))
> 
> 
> method <- c(data_df$method)
> n <- c(data_df$n)
> param <- vector("character", length(data_df$TPR))
> TPR <- c(data_df$TPR)
> FPR <- c(data_df$FPR)
> Precision <- c(data_df$Precision)
> 
> i <- 0
> while (i  < length(data_df$param)) {
+   param[i] <- p
+   i = i + 1
+ }
> 
> df <- data.frame(
+   method = as.factor(method),
+   n,
+   param = as.factor(param),
+   TPR,
+   FPR,
+   Precision
+ )
> 
> # Draw ROC curve
> df %>%
+   ggplot(aes(FPR, TPR, colour = method)) +
+   geom_line() +
+   geom_label(aes(label = n)) +
+   labs(title = "ROC curves", colour = "Model") +
+   theme_grey(base_size = 14)
> 
> # Draw precision / recall curve
> df %>%
+   ggplot(aes(TPR, Precision, colour = method)) +
+   geom_line() +
+   geom_label(aes(label = n))  +
+   labs(title = "Precision-Recall curves", colour = "Model") +
+   theme_grey(base_size = 14)

> # create data.frame from the list
> col_num <- 6
> row_num <- length(result) / col_num
> 
> data_matrix <- matrix(result, ncol = col_num, byrow = TRUE)
> colnames(data_matrix) <- c("method", "n", "param", "TPR", "FPR", "Precision")
> 
> data_df <- as.data.frame(data_matrix, row.names = NULL)
> data_df <- lapply(data_df, function(x) c(unlist(x)))
> 
> 
> method <- c(data_df$method)
> n <- c(data_df$n)
> param <- vector("character", length(data_df$TPR))
> TPR <- c(data_df$TPR)
> FPR <- c(data_df$FPR)
> Precision <- c(data_df$Precision)
> 
> i <- 1
> while (i  < length(data_df$param)) {
+   param[i] <- data_df$param[[i]]
+   i = i + 1
+ }
> 
> df <- data.frame(
+   method = as.factor(method),
+   n,
+   param = as.factor(param),
+   TPR,
+   FPR,
+   Precision
+ )
> 
> # Draw ROC curve
> df %>%
+   ggplot(aes(FPR, TPR, colour = method)) +
+   geom_line() +
+   geom_label(aes(label = n)) +
+   labs(title = "ROC curves", colour = "Model") +
+   theme_grey(base_size = 14)
> 
> # Draw precision / recall curve
> df %>%
+   ggplot(aes(TPR, Precision, colour = method)) +
+   geom_line() +
+   geom_label(aes(label = n))  +
+   labs(title = "Precision-Recall curves", colour = "Model") +
+   theme_grey(base_size = 14)
> 
> 
> 
> # ---------- Predictions (for all users): ---------- #
> 
> # get user recommendations and predict more books for him
> eval_recommender <- Recommender(
+   data = train.data, method = "RANDOM", parameter = NULL
+ )
> 
> rnd_idx <- sample(1:dim(known.data)[[1]], 1, replace=FALSE)
> predictions <- predict(
+   eval_recommender,
+   known.data[rnd_idx],
+   n = 10,
+ )
> 
> isbns <- getList(predictions)
> 
> # get the titles of the books
> load("recommender3.rdata")
> 
> books %>%
+   filter(ISBN %in% as.vector(isbns$`0`))
         ISBN                                                                                Book-Title       Book-Author
1  0590431692                                                             Hurray for Ali Baba Bernstein   Johanna Hurwitz
2  0140468811                                                               The New Read-Aloud Handbook      Jim Trelease
3  0452272785                                                                 In the Name of the Father      Gerry Conlon
4  0770427758                                                                           Drums of Autumn    Diana Gabaldon
5  0590455419                                                                         The Addams Family Elizabeth Faucher
6  0307101797 Walt Disney's The jungle book: Mowgli and the jungle animals (A First little golden book)        Cindy West
7  1551669552                                                                        Along Came Trouble     Sherryl Woods
8  0553269364                                                     Fatal Charms and Other Tales of Today    Dominick Dunne
9  0385499035                                                                      The Program: A Novel     Stephen White
10 0373168608                             Loving A Lonesome Cowboy (Harlequin American Romance, No 860)     Debbi Rawlins
   Year-Of-Publication                  Publisher
1                 1993 Scholastic Paperbacks (Mm)
2                 1989                Penguin USA
3                 1993                Penguin USA
4                 1997            Seal Press (WA)
5                 1991 Scholastic Paperbacks (Mm)
6                 1990            Western Pub. Co
7                 2002                       Mira
8                 1988                     Bantam
9                 2001            Doubleday Books
10                2001                  Harlequin
> dev.off()
RStudioGD 
        2 